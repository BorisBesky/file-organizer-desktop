name: "Build LLM Servers"

on:
  push:
    # Trigger when a new tag matching "llm-v*" is pushed
    tags:
      - 'llm-v*'
  
  # Allow manual trigger from the GitHub Actions tab
  workflow_dispatch:
    inputs:
      version:
        description: 'Version number (e.g., 1.0.0)'
        required: true
        default: '1.0.0'
      platforms:
        description: 'Platforms to build (comma-separated: windows,linux,macos or "all")'
        required: true
        default: 'all'

jobs:
  build-windows-ollama:
    runs-on: windows-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'windows')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install llama-cpp-python
          pip install fastapi uvicorn pydantic huggingface-hub
        
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/ollama/version.py << EOF
          """Version information for ollama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/windows/ollama
        run: |
          pyinstaller ollama_server.spec
          mv dist dist-cpu
      
      - name: Package artifact
        working-directory: llm-server/windows/ollama/dist-cpu
        run: |
          Compress-Archive -Path ollama_server -DestinationPath ollama_server-windows-cpu.zip
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ollama-server-windows-cpu
          path: llm-server/windows/ollama/dist-cpu/ollama_server-windows-cpu.zip
          retention-days: 30

  build-windows-ollama-vulkan:
    runs-on: windows-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'windows')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install https://github.com/BorisBesky/file-organizer-desktop/releases/download/v0.3.16/llama_cpp_python-0.3.16+vulkan-cp313-cp313-win_amd64.whl
          pip install fastapi uvicorn pydantic huggingface-hub
        
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/ollama/version.py << EOF
          """Version information for ollama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/windows/ollama
        run: |
          pyinstaller ollama_server.spec
          mv dist dist-vulkan
      
      - name: Package artifact
        working-directory: llm-server/windows/ollama/dist-vulkan
        run: |
          Compress-Archive -Path ollama_server -DestinationPath ollama_server-windows-vulkan.zip
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ollama-server-windows-vulkan
          path: llm-server/windows/ollama/dist-vulkan/ollama_server-windows-vulkan.zip
          retention-days: 30

  build-linux-ollama:
    runs-on: ubuntu-22.04
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'linux')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install llama-cpp-python
          pip install fastapi uvicorn pydantic huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/ollama/version.py << EOF
          """Version information for ollama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/linux/ollama
        run: pyinstaller ollama_server.spec
      
      - name: Package artifact
        working-directory: llm-server/linux/ollama/dist
        run: |
          tar -czf ollama_server-linux.tar.gz ollama_server
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ollama-server-linux
          path: llm-server/linux/ollama/dist/ollama_server-linux.tar.gz
          retention-days: 30

  build-linux-ollama-vulkan:
    runs-on: ubuntu-22.04
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'linux')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install https://github.com/BorisBesky/file-organizer-desktop/releases/download/v0.3.16/llama_cpp_python-0.3.16+vulkan-cp312-cp312-linux_x86_64.whl
          pip install fastapi uvicorn pydantic huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/linux/ollama/version.py << EOF
          """Version information for ollama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/linux/ollama
        run: |
          pyinstaller ollama_server.spec
          mv dist dist-vulkan
      
      - name: Package artifact
        working-directory: llm-server/linux/ollama/dist-vulkan
        run: |
          tar -czf ollama_server-linux-vulkan.tar.gz ollama_server
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ollama-server-linux-vulkan
          path: llm-server/linux/ollama/dist-vulkan/ollama_server-linux-vulkan.tar.gz
          retention-days: 30

  build-macos-mlx:
    runs-on: macos-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'macos')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install mlx mlx-lm
          pip install transformers tokenizers huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/macos/mlx/version.py << EOF
          """Version information for mlx_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/macos/mlx
        run: pyinstaller mlx_server.spec
      
      - name: Package artifact
        working-directory: llm-server/macos/mlx/dist
        run: |
          tar -czf mlx_server-macos.tar.gz mlx_server
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: mlx-server-macos
          path: llm-server/macos/mlx/dist/mlx_server-macos.tar.gz
          retention-days: 30

  create-release:
    needs: [build-windows-ollama, build-windows-ollama-vulkan, build-linux-ollama, build-macos-mlx]
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/llm-v')
    permissions:
      contents: write
    
    steps:
      - name: Prepare release metadata
        id: release_meta
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          VERSION: ${{ github.event.inputs.version }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          if [ "$EVENT_NAME" = "workflow_dispatch" ]; then
            echo "draft=true" >> "$GITHUB_OUTPUT"
            echo "tag_name=llm-v$VERSION" >> "$GITHUB_OUTPUT"
            echo "release_name=LLM Servers v$VERSION (draft)" >> "$GITHUB_OUTPUT"
            echo "target=$SHA" >> "$GITHUB_OUTPUT"
          else
            echo "draft=false" >> "$GITHUB_OUTPUT"
            echo "tag_name=$REF_NAME" >> "$GITHUB_OUTPUT"
            echo "release_name=LLM Servers $REF_NAME" >> "$GITHUB_OUTPUT"
            echo "target=$SHA" >> "$GITHUB_OUTPUT"
          fi

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.release_meta.outputs.tag_name }}
          name: ${{ steps.release_meta.outputs.release_name }}
          files: |
            artifacts/ollama-server-windows-cpu/ollama_server-windows-cpu.zip
            artifacts/ollama-server-windows-vulkan/ollama_server-windows-vulkan.zip
            artifacts/ollama-server-linux/ollama_server-linux.tar.gz
            artifacts/mlx-server-macos/mlx_server-macos.tar.gz
          draft: ${{ steps.release_meta.outputs.draft }}
          prerelease: false
          generate_release_notes: true
          target_commitish: ${{ steps.release_meta.outputs.target }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
