name: "Build LLM Servers"

on:
  push:
    # Trigger when a new tag matching "llm-v*" is pushed
    tags:
      - 'llm-v*'
  
  # Allow manual trigger from the GitHub Actions tab
  workflow_dispatch:
    inputs:
      version:
        description: 'Version number (e.g., 1.0.0)'
        required: true
        default: '1.0.0'
      platforms:
        description: 'Platforms to build (comma-separated: windows,linux,macos or "all")'
        required: true
        default: 'all'

jobs:
  build-windows-llama:
    runs-on: windows-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'windows')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install llama-cpp-python
          pip install fastapi uvicorn pydantic huggingface-hub
        
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/llama/version.py << EOF
          """Version information for llama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/windows/llama
        run: |
          pyinstaller llama_server.spec
          mv dist dist-cpu
      
      - name: Package artifact
        working-directory: llm-server/windows/llama/dist-cpu
        run: |
          Compress-Archive -Path llama_server -DestinationPath llama_server-windows-cpu.zip
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-windows-cpu
          path: llm-server/windows/llama/dist-cpu/llama_server-windows-cpu.zip
          retention-days: 30

  build-windows-llama-vulkan:
    runs-on: windows-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'windows')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install https://github.com/BorisBesky/file-organizer-desktop/releases/download/v0.3.16/llama_cpp_python-0.3.16+vulkan-cp313-cp313-win_amd64.whl
          pip install fastapi uvicorn pydantic huggingface-hub
        
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/llama/version.py << EOF
          """Version information for llama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/windows/llama
        run: |
          pyinstaller llama_server.spec
          mv dist dist-vulkan
      
      - name: Package artifact
        working-directory: llm-server/windows/llama/dist-vulkan
        run: |
          Compress-Archive -Path llama_server -DestinationPath llama_server-windows-vulkan.zip
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-windows-vulkan
          path: llm-server/windows/llama/dist-vulkan/llama_server-windows-vulkan.zip
          retention-days: 30

  build-linux-llama:
    runs-on: ubuntu-22.04
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'linux')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install llama-cpp-python
          pip install fastapi uvicorn pydantic huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/windows/llama/version.py << EOF
          """Version information for llama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/linux/llama
        run: pyinstaller llama_server.spec
      
      - name: Package artifact
        working-directory: llm-server/linux/llama/dist
        run: |
          tar -czf llama_server-linux-cpu.tar.gz llama_server
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-linux-cpu
          path: llm-server/linux/llama/dist/llama_server-linux-cpu.tar.gz
          retention-days: 30

  build-linux-llama-vulkan:
    runs-on: ubuntu-22.04
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'linux')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install https://github.com/BorisBesky/file-organizer-desktop/releases/download/v0.3.16/llama_cpp_python-0.3.16+vulkan-cp312-cp312-linux_x86_64.whl
          pip install fastapi uvicorn pydantic huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/linux/llama/version.py << EOF
          """Version information for llama_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Build with PyInstaller
        working-directory: llm-server/linux/llama
        run: |
          pyinstaller llama_server.spec
          mv dist dist-vulkan
      
      - name: Package artifact
        working-directory: llm-server/linux/llama/dist-vulkan
        run: |
          tar -czf llama_server-linux-vulkan.tar.gz llama_server
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-linux-vulkan
          path: llm-server/linux/llama/dist-vulkan/llama_server-linux-vulkan.tar.gz
          retention-days: 30

  build-macos-mlx:
    runs-on: macos-latest
    if: |
      github.event_name == 'push' || 
      contains(github.event.inputs.platforms, 'all') || 
      contains(github.event.inputs.platforms, 'macos')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller
          pip install mlx mlx-lm
          pip install transformers tokenizers huggingface-hub
      
      - name: Update version if manually triggered
        if: github.event_name == 'workflow_dispatch'
        run: |
          VERSION="${{ github.event.inputs.version }}"
          BUILD_DATE=$(date +%Y-%m-%d)
          echo "Updating version to $VERSION (build date: $BUILD_DATE)"
          cat > llm-server/macos/mlx/version.py << EOF
          """Version information for mlx_server."""
          
          __version__ = "$VERSION"
          __build_date__ = "$BUILD_DATE"
          EOF
      
      - name: Prepare macOS signing keychain
        shell: bash
        env:
          APPLE_CERT_BASE64: ${{ secrets.APPLE_CERTIFICATE }}
          APPLE_CERT_PASSWORD: ${{ secrets.APPLE_CERTIFICATE_PASSWORD }}
          KEYCHAIN_PASSWORD: pyinstaller-build
        run: |
          set -euo pipefail
          
          KEYCHAIN_PATH="$HOME/Library/Keychains/pyinstaller-build.keychain-db"
          CERT_P12_TMP="$(mktemp -t pyinstaller-cert-XXXX).p12"

          # Decode cert to a temp file
          echo "$APPLE_CERT_BASE64" | base64 --decode > "$CERT_P12_TMP"

          # Create and unlock keychain at full predictable path
          security create-keychain -p "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"
          security unlock-keychain -p "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"
          security set-keychain-settings -t 3600 -u "$KEYCHAIN_PATH"

          # Import the p12 and allow codesign/pkgbuild/productbuild to access it
          security import "$CERT_P12_TMP" -k "$KEYCHAIN_PATH" -P "$APPLE_CERT_PASSWORD" \
            -T /usr/bin/codesign -T /usr/bin/pkgbuild -T /usr/bin/productbuild

          # Ensure keychain is in the user's keychain list (use login + our keychain)
          security list-keychains -d user -s "$HOME/Library/Keychains/login.keychain-db" "$KEYCHAIN_PATH"

          # Ensure codesign can access the private key (partition list)
          security set-key-partition-list -S apple-tool:,apple:,codesign: -s -k "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"

          # Extract the first identity CN and export it for subsequent steps
          APPLE_SIGNING_IDENTITY=$(security find-identity -v -p codesigning | awk -F\" 'NR==1{print $2}')
          echo "APPLE_SIGNING_IDENTITY=$APPLE_SIGNING_IDENTITY" >> "$GITHUB_ENV"

      - name: Build with PyInstaller
        working-directory: llm-server/macos/mlx
        run: pyinstaller --codesign-identity "$APPLE_SIGNING_IDENTITY" --osx-entitlements-file entitlements.plist mlx_server.spec

      - name: Notarize the app
        working-directory: llm-server/macos/mlx/dist
        env:
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_ID_PASSWORD: ${{ secrets.APPLE_PASSWORD }}
          APPLE_TEAM_ID: ${{ secrets.APPLE_TEAM_ID }}
        run: |
          zip -r mlx_server-macos.zip mlx_server
          xcrun notarytool submit mlx_server-macos.zip --apple-id "$APPLE_ID" --password "$APPLE_ID_PASSWORD" --team-id "$APPLE_TEAM_ID" --wait
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: mlx-server-macos
          path: llm-server/macos/mlx/dist/mlx_server-macos.zip
          retention-days: 30

  create-release:
    needs: [build-windows-llama, build-windows-llama-vulkan, build-linux-llama, build-linux-llama-vulkan, build-macos-mlx]
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/llm-v')
    permissions:
      contents: write
    
    steps:
      - name: Prepare release metadata
        id: release_meta
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          VERSION: ${{ github.event.inputs.version }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          if [ "$EVENT_NAME" = "workflow_dispatch" ]; then
            echo "draft=true" >> "$GITHUB_OUTPUT"
            echo "tag_name=llm-v$VERSION" >> "$GITHUB_OUTPUT"
            echo "release_name=LLM Servers v$VERSION (draft)" >> "$GITHUB_OUTPUT"
            echo "target=$SHA" >> "$GITHUB_OUTPUT"
          else
            echo "draft=false" >> "$GITHUB_OUTPUT"
            echo "tag_name=$REF_NAME" >> "$GITHUB_OUTPUT"
            echo "release_name=LLM Servers $REF_NAME" >> "$GITHUB_OUTPUT"
            echo "target=$SHA" >> "$GITHUB_OUTPUT"
          fi

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.release_meta.outputs.tag_name }}
          name: ${{ steps.release_meta.outputs.release_name }}
          files: |
            artifacts/llama-server-windows-cpu/llama_server-windows-cpu.zip
            artifacts/llama-server-windows-vulkan/llama_server-windows-vulkan.zip
            artifacts/llama-server-linux/llama_server-linux-cpu.tar.gz
            artifacts/llama-server-linux-vulkan/llama_server-linux-vulkan.tar.gz
            artifacts/mlx-server-macos/mlx_server-macos.tar.gz
          draft: ${{ steps.release_meta.outputs.draft }}
          prerelease: false
          generate_release_notes: true
          target_commitish: ${{ steps.release_meta.outputs.target }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
